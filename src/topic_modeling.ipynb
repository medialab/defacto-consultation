{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e6661e8",
   "metadata": {},
   "source": [
    "# Install dependencies in a virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c2b061",
   "metadata": {},
   "source": [
    "Install packages for efficiently parsing CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install casanova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09059b10",
   "metadata": {},
   "source": [
    "Install packages for NLP analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertopic==0.13.0 hdbscan nltk sentence_transformers scikit-learn umap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165cb01",
   "metadata": {},
   "source": [
    "Also install `protobuf` version 3.20 because `SentenceTransformer` needs it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eccb4de",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "We're going to be taking advantage of transformers and word-embedding, which in theory do not require pre-processing sentences that are sent to the topic model. Nevertheless, some pre-processing can be useful (i.e. removing HTML tags). In our case, we will want to remove the phrase \"Il faut\" at the start of every proposition because it is not meaningful in the context of our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe952b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATAFILE = \"mieux-sinformer.csv\" # change this according to file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90f639fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def special_preprocessing(string):\n",
    "    string = string.lower()\n",
    "    bow = string.split()\n",
    "    if bow[:2] == [\"il\", \"faut\"]:\n",
    "        bow = bow[2:]\n",
    "    return \" \".join(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32916727",
   "metadata": {},
   "source": [
    "With that helper function in place, we'll parse our data file and create a list of our documents. (list of strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451f8f26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset includes 1723 docs.\n"
     ]
    }
   ],
   "source": [
    "import casanova\n",
    "\n",
    "def get_docs(DATAFILE):\n",
    "    with open(DATAFILE) as f:\n",
    "        reader = casanova.reader(f)\n",
    "        docs = [special_preprocessing(cell) for cell in reader.cells(column=\"Proposition\")]\n",
    "        print(f\"Dataset includes {len(docs)} docs.\")\n",
    "        return docs\n",
    "\n",
    "docs = get_docs(DATAFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d499a96",
   "metadata": {},
   "source": [
    "We will also need to prepare a list of stop words, which will be excluded from the topics' representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f2abbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stoplist = stopwords.words(\"french\")\n",
    "ADDITIONAL_STOPWORDS = [\"plus\", \"chaque\", \"tout\", \"tous\", \"toutes\", \"toute\", \"leur\", \"leurs\", \"comme\", \"afin\", \"pendant\", \"lorsque\"]\n",
    "stoplist.extend(ADDITIONAL_STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98236674",
   "metadata": {},
   "source": [
    "# Vectorize the data\n",
    "\n",
    "### Word embeddings\n",
    "The first step is to transform a string (sentence) into an array of numbers (vector) or in other words, to \"vectorize\" the text. There are many ways to do this. By default, `BERTopic`'s privileges word embeddings, which are currently the most powerful way to encode a document because they represent words' relationships to other words in the context of a sentence.\n",
    "\n",
    "However, `BERTopic`'s default sentence transformer was trained on English-language texts. Because we are working with a corpus of sentences exclusively in French, we want to take advantage of a language model trained on French-language texts, such as the `CamemBERT` model. Fortunately, a data scientist at *La Javaness* Van Tuan Dang (\"dangvantuan\" on HuggingFace) has trained and published a sentence transformer model based on the `CamemBERT` base model. We will simply import this pre-trained transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17030859",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/kelly.christensen/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0e54477766474b8e1fb1655ac16911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 has 22 characters, and the embedding is 1024 long.\n",
      "Sentence 2 has 7 characters, and the embedding is 1024 long.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentences = ['Bonjour tout le monde.', 'Ça va ?']\n",
    "\n",
    "camembert_sentence_transformer = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")\n",
    "example_embeddings = camembert_sentence_transformer.encode(sentences, show_progress_bar=True)\n",
    "\n",
    "print(f\"Sentence 1 has {len(sentences[0])} characters, and the embedding is {len(example_embeddings[0])} long.\")\n",
    "print(f\"Sentence 2 has {len(sentences[1])} characters, and the embedding is {len(example_embeddings[1])} long.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b35d2",
   "metadata": {},
   "source": [
    "As seen in the cell above, the embeddings created by Dang's sentence transformer `sentence-camembert-large` have the same length, despite the fact that the sentences the arrays represent are different lenghts. The embeddings have the same length because, rather than directly representing words as numbers (aka bag of words), the transformer creates a rich representation that takes into account 1024 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f185f96",
   "metadata": {},
   "source": [
    "### Construct the topic model with the desired parameters\n",
    "\n",
    "Finally, having decided on an effective embedding model (very important!) and produced stop words for the topics' representations, we're ready to assemble the topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90258ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "stoplist = stopwords.words(\"french\")\n",
    "ADDITIONAL_STOPWORDS = [\"plus\", \"chaque\", \"tout\", \"tous\", \"toutes\", \"toute\", \"leur\", \"leurs\", \"comme\", \"afin\", \"pendant\", \"lorsque\"]\n",
    "\n",
    "def set_model_parameters(embedding_model):\n",
    "\n",
    "    # Step 1 - Extract embeddings\n",
    "    embedding_model = embedding_model\n",
    "\n",
    "    # Step 2 - Reduce dimensionality\n",
    "    umap_model = UMAP(angular_rp_forest=True, metric='cosine', n_components=10, n_neighbors=30, min_dist=0.1)\n",
    "\n",
    "    # Step 3 - Cluster reduced embeddings\n",
    "    hdbscan_model = HDBSCAN(min_cluster_size=13, min_samples=3, prediction_data=True, metric='euclidean', cluster_selection_method='eom')\n",
    "\n",
    "    # Step 4 - Tokenize topics\n",
    "    stoplist.extend(ADDITIONAL_STOPWORDS)\n",
    "    vectorizer_model = CountVectorizer(stop_words=stoplist, ngram_range=(1, 3))\n",
    "\n",
    "    # Step 5 - Create topic representation\n",
    "    ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True, bm25_weighting=True)\n",
    "\n",
    "    # Topic model\n",
    "    return BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        ctfidf_model=ctfidf_model,\n",
    "        diversity=0.5,\n",
    "        n_gram_range=(1,3),\n",
    "        nr_topics='auto'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00dd83",
   "metadata": {},
   "source": [
    "# Fit the topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2be5a1",
   "metadata": {},
   "source": [
    "Download the pre-trained embedding model from `SentenceTransformers` and attribute it to the variable `embedding model`. Then use that model to encode all the documents in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb4b5c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/kelly.christensen/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d41b5c0578a41ab904b84fbfb173037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")\n",
    "embeddings = camembert_sentence_transformer.encode(docs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75196a5c",
   "metadata": {},
   "source": [
    "Create an instance of the model with all the parameters defined and our selected embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d605d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_model = set_model_parameters(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f4816",
   "metadata": {},
   "source": [
    "Fit the model to the documents in our corpus and to the embeddings we prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "773525a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bertopic._bertopic.BERTopic at 0x33fabe800>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.fit(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5842f10-5856-48e9-8e29-c0e2f678752c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-1  --  sans  --  journalistes  --  sociaux  --  médias  --  sujets',\n",
       " '0  --  école  --  esprit critique  --  éducation médias information  --  développer  --  apprendre',\n",
       " '1  --  financement  --  concentration médias  --  milliardaires  --  indépendance médias  --  service public',\n",
       " '2  --  buzz  --  journalistes  --  faits divers  --  sujets  --  arrêter',\n",
       " '3  --  sanctionner  --  fake news  --  pubs  --  supprimer anonymat  --  arnaques',\n",
       " '4  --  rendre accessible  --  acheter  --  payer  --  presse écrite  --  netflix',\n",
       " '5  --  charte munich  --  déontologie journalistique  --  professionnelle  --  ordre  --  conseil déontologie',\n",
       " '6  --  gauche  --  orientation  --  lfi  --  partiaux  --  partis',\n",
       " '7  --  nutriscore  --  créer label  --  mettre place  --  score fiabilité  --  ia',\n",
       " '8  --  fake news médias  --  news créer  --  chargé  --  unité  --  dénoncer',\n",
       " '9  --  modérer  --  bulles filtre  --  confortent  --  réseaux sociaux favorisent  --  encadrer algorithmes',\n",
       " '10  --  france  --  ue  --  autres pays  --  créer chaine  --  tnt',\n",
       " '11  --  emploi temps  --  temps élèves  --  enseignement emi professeurs  --  donner moyens professeurs  --  documentalistes enseigner emi',\n",
       " '12  --  continu  --  chaînes information continu  --  quota  --  france  --  supprimer concept information',\n",
       " '13  --  suivi  --  prismes historiques scientifiques  --  privilégier différents éclairages  --  proposer petit  --  recontextualiser cours']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.generate_topic_labels(nr_words=5, topic_prefix=True, word_length=None, separator='  --  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b275aa6-6d95-4c58-a2c8-8e7e6c83b384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>572</td>\n",
       "      <td>-1_sans_journalistes_sociaux_médias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>0_école_esprit critique_éducation médias infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>1_financement_concentration médias_milliardair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>2_buzz_journalistes_faits divers_sujets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>3_sanctionner_fake news_pubs_supprimer anonymat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>4_rendre accessible_acheter_payer_presse écrite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>5_charte munich_déontologie journalistique_pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>6_gauche_orientation_lfi_partiaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>7_nutriscore_créer label_mettre place_score fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>8_fake news médias_news créer_chargé_unité</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>9_modérer_bulles filtre_confortent_réseaux soc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>10_france_ue_autres pays_créer chaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>11_emploi temps_temps élèves_enseignement emi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>12_continu_chaînes information continu_quota_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>13_suivi_prismes historiques scientifiques_pri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                               Name\n",
       "0      -1    572                -1_sans_journalistes_sociaux_médias\n",
       "1       0    310  0_école_esprit critique_éducation médias infor...\n",
       "2       1    223  1_financement_concentration médias_milliardair...\n",
       "3       2    149            2_buzz_journalistes_faits divers_sujets\n",
       "4       3    137    3_sanctionner_fake news_pubs_supprimer anonymat\n",
       "5       4     69    4_rendre accessible_acheter_payer_presse écrite\n",
       "6       5     47  5_charte munich_déontologie journalistique_pro...\n",
       "7       6     45                  6_gauche_orientation_lfi_partiaux\n",
       "8       7     35  7_nutriscore_créer label_mettre place_score fi...\n",
       "9       8     33         8_fake news médias_news créer_chargé_unité\n",
       "10      9     29  9_modérer_bulles filtre_confortent_réseaux soc...\n",
       "11     10     29              10_france_ue_autres pays_créer chaine\n",
       "12     11     16  11_emploi temps_temps élèves_enseignement emi ...\n",
       "13     12     15  12_continu_chaînes information continu_quota_f...\n",
       "14     13     14  13_suivi_prismes historiques scientifiques_pri..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5f64ad4-cd34-48e5-a02e-017333e9c1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = str(date.today())\n",
    "\n",
    "topic_model.save(f'models/{today}_bertopic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c10732",
   "metadata": {},
   "source": [
    "### Explore the model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a28bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "# if loading saved model, run cells 6 and 7\n",
    "\n",
    "topic_model = BERTopic.load('models/13-03-2023_bertopic.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bab0ba77-cc65-43f7-88cc-75b9059dd6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1620px\"\n",
       "    height=\"1020\"\n",
       "    src=\"iframe_figures/figure_14.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model = BERTopic.load('models/13-03-2023_bertopic.model')\n",
    "topics_to_merge = [\n",
    "    [3,4,6],[3,15]\n",
    "]\n",
    "topic_model.merge_topics(docs, topics_to_merge)\n",
    "topics_to_merge = [\n",
    "    [4,12]\n",
    "]\n",
    "topic_model.merge_topics(docs, topics_to_merge)\n",
    "barchart = topic_model.visualize_barchart(top_n_topics=17, title=\"<b>Représentation des topics</b>\", width=400, n_words=7)\n",
    "\n",
    "# barchart.write_html('topic_visualisations/barchart.html')\n",
    "barchart.show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e18feef-144b-44ce-8d07-fd5c7a34e6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>569</td>\n",
       "      <td>-1_sans_éducation médias_jeunes_donner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>0_journalistes_politiques_sujets_débats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>1_financement_concentration médias_milliardair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>2_fake news_vérifiée_qualité_plusieurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>152</td>\n",
       "      <td>3_réseaux sociaux_éducation médias information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>4_esprit_développer_développer esprit critique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>5_rendre accessible_papier_abonnements gratuit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>6_europe_chaînes information continu_france té...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>7_news_propos_diffusant_élus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>8_éthique_charte munich_déontologie journalist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>9_anonymat réseaux sociaux_réseaux sociaux int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10_sanctionner youtube lorsqu_pubs arnaques_mé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>11_médias locaux_web_niveau local retrouver_na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>12_emploi temps élèves_emi professeurs_élèves_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                               Name\n",
       "0      -1    569             -1_sans_éducation médias_jeunes_donner\n",
       "1       0    263            0_journalistes_politiques_sujets_débats\n",
       "2       1    210  1_financement_concentration médias_milliardair...\n",
       "3       2    178             2_fake news_vérifiée_qualité_plusieurs\n",
       "4       3    152  3_réseaux sociaux_éducation médias information...\n",
       "5       4     85  4_esprit_développer_développer esprit critique...\n",
       "6       5     51  5_rendre accessible_papier_abonnements gratuit...\n",
       "7       6     47  6_europe_chaînes information continu_france té...\n",
       "8       7     46                       7_news_propos_diffusant_élus\n",
       "9       8     45  8_éthique_charte munich_déontologie journalist...\n",
       "10      9     24  9_anonymat réseaux sociaux_réseaux sociaux int...\n",
       "11     10     20  10_sanctionner youtube lorsqu_pubs arnaques_mé...\n",
       "12     11     17  11_médias locaux_web_niveau local retrouver_na...\n",
       "13     12     16  12_emploi temps élèves_emi professeurs_élèves_..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c3befc9-70fe-4d35-a0b0-f21987627ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"3220px\"\n",
       "    height=\"1020\"\n",
       "    src=\"iframe_figures/figure_16.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_labels_dict = {\n",
    "    0:\"L'opinion & le journalisme\",\n",
    "    1:\"Financement & l'indépendance des médias\",\n",
    "    2:\"Désinformation\",\n",
    "    3:\"Formation au secondaire\",\n",
    "    4:\"Formation au primaire\",\n",
    "    5:\"Accès à l'information\",\n",
    "    6:\"Chaînes d'information en continu\",\n",
    "    7:\"Législation\",\n",
    "    8:\"Éthique du journalisme\",\n",
    "    9:\"Désanoymisation en ligne\",\n",
    "    10:\"Arnaques & influenceurs\",\n",
    "    11:\"Échelles des médias\",\n",
    "    12:\"Enseignement & l'EMI\"   \n",
    "}\n",
    "\n",
    "topic_model.set_topic_labels(topic_labels_dict)\n",
    "barchart = topic_model.visualize_barchart(top_n_topics=17, custom_labels=True, title=\"<b>Représentation des topics</b>\", width=800, n_words=7)\n",
    "\n",
    "# barchart.write_html('../docs/topic_visualisations/barchart.html')\n",
    "barchart.show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d163e65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:05<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "├─réseaux_professeurs documentalistes_esprit critique_emi_jeunes\n",
      "│    ├─■──esprit_développer_développer esprit critique_analyser_âge ── Topic: 4\n",
      "│    └─réseaux sociaux_professeurs documentalistes_emi_éducation médias information_algorithmes\n",
      "│         ├─■──réseaux sociaux_éducation médias information_professeurs documentalistes_algorithmes_responsables ── Topic: 3\n",
      "│         └─■──emploi temps élèves_emi professeurs_élèves_donner moyens professeurs_enseignement emi ── Topic: 12\n",
      "└─journalistes_média_créer_indépendants_interdire\n",
      "     ├─pubs_arnaques_identité_fake news_auteurs\n",
      "     │    ├─■──anonymat réseaux sociaux_réseaux sociaux interdire_sociaux interdire_supprimer_vrai nom ── Topic: 9\n",
      "     │    └─pubs_arnaques_fake news_auteurs_financièrement\n",
      "     │         ├─■──news_propos_diffusant_élus_sanctionner médias ── Topic: 7\n",
      "     │         └─■──sanctionner youtube lorsqu_pubs arnaques_médias informations_influenceurs_pub institutionnelles déno ── Topic: 10\n",
      "     └─journalistes_média_sources_créer_arrêter\n",
      "          ├─journalistes_média_créer_arrêter_indépendants\n",
      "          │    ├─■──éthique_charte munich_déontologie journalistique_respect_professionnelle ── Topic: 8\n",
      "          │    └─médias_journalistes_arrêter_financement_indépendants\n",
      "          │         ├─journalistes_presse_financement_entre_indépendants\n",
      "          │         │    ├─■──europe_chaînes information continu_france télévision_créer chaine_affranchir ── Topic: 6\n",
      "          │         │    └─journalistes_presse_informations_financement_indépendants\n",
      "          │         │         ├─journalistes_sujets_politique_arrêter_fake news\n",
      "          │         │         │    ├─■──fake news_vérifiée_qualité_plusieurs_sources information ── Topic: 2\n",
      "          │         │         │    └─■──journalistes_politiques_sujets_débats_arrêtent ── Topic: 0\n",
      "          │         │         └─■──financement_concentration médias_milliardaires_interdire_grands groupes ── Topic: 1\n",
      "          │         └─■──rendre accessible_papier_abonnements gratuits_beaucoup_établissements scolaires ── Topic: 5\n",
      "          └─■──médias locaux_web_niveau local retrouver_nationales internationales publier_notoriété légitimité moi ── Topic: 11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "\n",
    "tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9a4d712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:05<00:00,  2.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1220px\"\n",
       "    height=\"415\"\n",
       "    src=\"iframe_figures/figure_18.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "\n",
    "hierarchy = topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics, width=1200, custom_labels=topic_labels_dict)\n",
    "\n",
    "# hierarchy.write_html('../docs/topic_visualisations/hierarchy.html')\n",
    "hierarchy.show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "949ace67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1220px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_19.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = topic_model.visualize_heatmap(n_clusters=6, custom_labels=topic_labels_dict, width=1200)\n",
    "\n",
    "# heatmap.write_html('../docs/topic_visualisations/heatmap.html')\n",
    "heatmap.show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78bf41be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_20.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_term_rank(log_scale=True).show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efde642d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"670px\"\n",
       "    height=\"670\"\n",
       "    src=\"iframe_figures/figure_21.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_topics().show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab85f6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/kelly.christensen/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8735cfaa48b462f8147a84aa7d77636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/kelly.christensen/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)\n",
    "\n",
    "camembert_sentence_transformer = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95c4e19e-808d-4736-9a5f-893939675543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1820px\"\n",
       "    height=\"770\"\n",
       "    src=\"iframe_figures/figure_23.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_visualisation = topic_model.visualize_documents(docs=docs, reduced_embeddings=reduced_embeddings, width=1800, height=750, sample=0.1, custom_labels=topic_labels_dict)\n",
    "\n",
    "# doc_visualisation.write_html('../docs/topic_visualisations/doc_visualisation.html')\n",
    "doc_visualisation.show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f5b55",
   "metadata": {},
   "source": [
    "Print the results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "689716ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import casanova\n",
    "\n",
    "PREDICTIONS_FILE = 'bertopic_topics_notebook.csv'\n",
    "\n",
    "results = topic_model.get_document_info(docs=docs)\n",
    "results.to_csv()\n",
    "with open(DATAFILE) as f, open(PREDICTIONS_FILE, 'w') as of:\n",
    "    enricher = casanova.enricher(f, of, add=[\"document\", \"topic\", \"name\", \"custom_name\", \"top_n_words\", \"probability\", \"representative_document\"])\n",
    "    for i, row in enumerate(enricher):\n",
    "        enricher.writerow(row=row, add=[results[\"Document\"][i], results[\"Topic\"][i], results[\"Name\"][i], results[\"CustomName\"][i], results[\"Top_n_words\"][i], results[\"Probability\"][i], results[\"Representative_document\"][i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
